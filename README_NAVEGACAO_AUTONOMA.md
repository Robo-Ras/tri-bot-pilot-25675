# Sistema de NavegaÃ§Ã£o AutÃ´noma com Intel RealSense

Sistema completo de controle remoto e navegaÃ§Ã£o autÃ´noma para robÃ´ utilizando sensores Intel RealSense L515 (LiDAR) e D435 (cÃ¢mera RGB-D).

## ğŸ“‹ Requisitos

### Hardware
- **Notebook** com portas USB 3.0+
- **Intel RealSense L515** (LiDAR)
- **Intel RealSense D435** (CÃ¢mera RGB-D)
- **Arduino** conectado ao robÃ´
- **RobÃ´ com 3 motores** conforme especificaÃ§Ã£o do projeto

### Software
- Python 3.8+
- Bibliotecas Python (instalaÃ§Ã£o abaixo)
- Navegador web moderno (Chrome, Edge, Firefox)

## ğŸš€ InstalaÃ§Ã£o

### 1. Instalar DependÃªncias Python

```bash
pip install -r requirements.txt
```

Ou instale manualmente:

```bash
pip install pyrealsense2 pyserial websockets opencv-python numpy
```

### 2. Verificar Sensores

Execute para listar dispositivos RealSense conectados:

```bash
python -c "import pyrealsense2 as rs; ctx = rs.context(); print([dev.get_info(rs.camera_info.name) for dev in ctx.query_devices()])"
```

Deve mostrar: `['Intel RealSense L515', 'Intel RealSense D435']`

### 3. Configurar Arduino

Carregue o cÃ³digo `arduino_robot_control.ino` no Arduino e anote a porta serial (ex: COM3, /dev/ttyUSB0).

## ğŸ® Como Usar

### Passo 1: Iniciar o Sistema no Notebook

Execute o script Python principal:

```bash
python robot_autonomous_control.py
```

VocÃª verÃ¡:

```
=== Sistema de Controle AutÃ´nomo ===

Inicializando sensores...
âœ“ LiDAR L515 iniciado
âœ“ CÃ¢mera D435 iniciada
âœ“ Servidor WebSocket rodando em ws://localhost:8765
```

### Passo 2: Abrir Interface Web

1. Abra o navegador e acesse a interface do projeto
2. A interface se conectarÃ¡ automaticamente ao notebook via WebSocket
3. Quando conectado, verÃ¡ o status "Conectado ao Notebook"

### Passo 3: Conectar ao Arduino

Na interface web:
1. O sistema detectarÃ¡ automaticamente a porta do Arduino
2. Clique em "Conectar Arduino" se necessÃ¡rio
3. Aguarde confirmaÃ§Ã£o de conexÃ£o

### Passo 4: Ativar NavegaÃ§Ã£o AutÃ´noma

1. **Modo Manual** (padrÃ£o):
   - Use os controles direcionais para mover o robÃ´
   - Ou ajuste a velocidade individual de cada motor

2. **Modo AutÃ´nomo**:
   - Ative o switch "Modo AutÃ´nomo"
   - O robÃ´ comeÃ§arÃ¡ a navegar automaticamente
   - DesviarÃ¡ de obstÃ¡culos detectados pelo LiDAR
   - Override manual disponÃ­vel a qualquer momento

## ğŸ“Š Interface de VisualizaÃ§Ã£o

### CÃ¢mera D435
- Feed de vÃ­deo em tempo real
- VisualizaÃ§Ã£o colorida do ambiente
- Taxa de atualizaÃ§Ã£o: ~10 FPS

### Mapa de ObstÃ¡culos (LiDAR L515)
Dividido em 3 setores:

- **Esquerda**: DistÃ¢ncia e status de obstÃ¡culos Ã  esquerda
- **Centro**: DistÃ¢ncia e status de obstÃ¡culos Ã  frente
- **Direita**: DistÃ¢ncia e status de obstÃ¡culos Ã  direita

**Cores:**
- ğŸŸ¢ Verde: Caminho livre (> 0.8m)
- ğŸ”´ Vermelho: ObstÃ¡culo detectado (< 0.8m)

## ğŸ¤– LÃ³gica de NavegaÃ§Ã£o AutÃ´noma

### Algoritmo de Desvio

```
1. Verifica setor central
   â”œâ”€ Livre? â†’ AvanÃ§ar
   â””â”€ Bloqueado? â†’ PrÃ³ximo passo

2. Verifica setor direito
   â”œâ”€ Livre? â†’ Virar direita
   â””â”€ Bloqueado? â†’ PrÃ³ximo passo

3. Verifica setor esquerdo
   â”œâ”€ Livre? â†’ Virar esquerda
   â””â”€ Bloqueado? â†’ Recuar

4. Loop a cada 100ms
```

### ParÃ¢metros AjustÃ¡veis

No arquivo `robot_autonomous_control.py`:

```python
# DistÃ¢ncia segura (metros)
detector = ObstacleDetector(safe_distance=0.8)

# Velocidades
direction, speed = navigator.decide_movement(obstacles)
# forward: 150
# turn: 120
# backward: 100
```

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### Ajustar Sensibilidade do LiDAR

```python
# Em ObstacleDetector.__init__
self.safe_distance = 0.5  # Mais sensÃ­vel
self.safe_distance = 1.2  # Menos sensÃ­vel
```

### Ajustar Taxa de AtualizaÃ§Ã£o

```python
# Em WebSocketServer.sensor_loop
await asyncio.sleep(0.1)  # 10 Hz (padrÃ£o)
await asyncio.sleep(0.05) # 20 Hz (mais rÃ¡pido)
```

### Ajustar Qualidade do VÃ­deo

```python
# Em WebSocketServer.sensor_loop
cv2.imencode('.jpg', color_image, [cv2.IMWRITE_JPEG_QUALITY, 50])
#                                                           â†‘
#                                                        30-100
```

## ğŸ”¥ ResoluÃ§Ã£o de Problemas

### Erro: "Failed to set power state"
**SoluÃ§Ã£o**: Desconecte e reconecte os sensores RealSense

### Erro: "No device connected"
**SoluÃ§Ã£o**: Verifique portas USB 3.0+ e drivers Intel RealSense

### WebSocket nÃ£o conecta
**SoluÃ§Ã£o**: 
- Verifique se o script Python estÃ¡ rodando
- Confirme que a porta 8765 estÃ¡ livre
- Use `ws://localhost:8765` no cÃ³digo

### CÃ¢mera nÃ£o aparece
**SoluÃ§Ã£o**:
- Verifique logs do Python para erros
- Confirme que o D435 estÃ¡ inicializado corretamente

### LiDAR nÃ£o detecta obstÃ¡culos
**SoluÃ§Ã£o**:
- Verifique se hÃ¡ objetos na frente (mÃ­nimo 10cm)
- Confirme que o L515 estÃ¡ inicializado
- Ajuste `safe_distance` se necessÃ¡rio

## ğŸ“¡ Protocolo de ComunicaÃ§Ã£o

### WebSocket Messages (Python â†’ Interface)

```json
{
  "type": "sensor_data",
  "timestamp": 1234567890.123,
  "camera": "base64_encoded_jpeg",
  "obstacles": {
    "left": false,
    "center": true,
    "right": false,
    "distances": {
      "left": 1.23,
      "center": 0.45,
      "right": 2.10
    }
  }
}
```

### WebSocket Messages (Interface â†’ Python)

```json
// Mover manualmente
{
  "type": "move",
  "m1": 150,
  "m2": 150,
  "m3": 150
}

// Ativar/desativar autÃ´nomo
{
  "type": "set_autonomous",
  "enabled": true
}

// Obter portas disponÃ­veis
{
  "type": "get_ports"
}

// Conectar ao Arduino
{
  "type": "connect",
  "port": "COM3"
}
```

## ğŸ¯ PrÃ³ximos Passos

- [ ] Implementar mapeamento do ambiente (SLAM)
- [ ] Adicionar gravaÃ§Ã£o de trajetos
- [ ] Implementar reconhecimento de objetos com IA
- [ ] Adicionar controle de voz
- [ ] Implementar planejamento de rota A*

## ğŸ“š DocumentaÃ§Ã£o Adicional

- [Intel RealSense SDK](https://github.com/IntelRealSense/librealsense)
- [PyRealSense2 Docs](https://intelrealsense.github.io/librealsense/python_docs/)
- [DocumentaÃ§Ã£o TÃ©cnica Completa](./DOCUMENTACAO_TECNICA.md)

## ğŸ¤ Contribuindo

SugestÃµes e melhorias sÃ£o bem-vindas! Veja os arquivos:
- `robot_autonomous_control.py` - Sistema principal
- `src/components/SensorVisualization.tsx` - Interface dos sensores
- `src/components/AutonomousControl.tsx` - Controles de autonomia

---

**Desenvolvido com â¤ï¸ usando Intel RealSense, Python e React**
